Boston$crim
Boston$zn
Boston
coefficients(lm.zn)[2]
coefficients(lm.zn)
lm.fit.all
coefficients(lm.fit.all)[2:14]
x = c(coefficients(lm.zn)[2],
coefficients(lm.indus)[2],
coefficients(lm.chas)[2],
coefficients(lm.nox)[2],
coefficients(lm.rm)[2],
coefficients(lm.age)[2],
coefficients(lm.dis)[2],
coefficients(lm.rad)[2],
coefficients(lm.tax)[2],
coefficients(lm.ptratio)[2],
coefficients(lm.black)[2],
coefficients(lm.lstat)[2],
coefficients(lm.medv)[2])
library(MASS)
summary(Boston)
Boston$chas <- factor(Boston$chas, labels = c("N","Y"))
summary(Boston)
attach(Boston)
lm.zn = lm(crim~zn)
summary(lm.zn) # yes
lm.indus = lm(crim~indus)
summary(lm.indus) # yes
lm.chas = lm(crim~chas)
summary(lm.chas) # no
lm.nox = lm(crim~nox)
summary(lm.nox) # yes
lm.rm = lm(crim~rm)
summary(lm.rm) # yes
lm.age = lm(crim~age)
summary(lm.age) # yes
lm.dis = lm(crim~dis)
summary(lm.dis) # yes
lm.rad = lm(crim~rad)
summary(lm.rad) # yes
lm.tax = lm(crim~tax)
summary(lm.tax) # yes
lm.ptratio = lm(crim~ptratio)
summary(lm.ptratio) # yes
lm.black = lm(crim~black)
summary(lm.black) # yes
lm.lstat = lm(crim~lstat)
summary(lm.lstat) # yes
lm.medv = lm(crim~medv)
summary(lm.medv) # yes
x = c(coefficients(lm.zn)[2],
coefficients(lm.indus)[2],
coefficients(lm.chas)[2],
coefficients(lm.nox)[2],
coefficients(lm.rm)[2],
coefficients(lm.age)[2],
coefficients(lm.dis)[2],
coefficients(lm.rad)[2],
coefficients(lm.tax)[2],
coefficients(lm.ptratio)[2],
coefficients(lm.black)[2],
coefficients(lm.lstat)[2],
coefficients(lm.medv)[2])
y = coefficients(lm.fit.all)[2:14]
plot(x, y)
lm.zn = lm(crim~poly(zn,3))
summary(lm.zn) # 1, 2
lm.indus = lm(crim~poly(indus,3))
summary(lm.indus) # 1, 2, 3
lm.nox = lm(crim~poly(nox,3))
Boston$nox
coefficients(lm.medv)[2]
lm.nox = lm(crim~nox)
summary(lm.nox)
lm.black = lm(crim~poly(black,3))
summary(lm.black)
lm.rad = lm(crim~poly(rad,3))
summary(lm.rad)
lm.indus = lm(crim~poly(indus))
lm.indus
lm.rad = lm(crim~poly(rad,3))
lm.rad
lm.dis = lm(crim~poly(dis,3))
lm.dis
lm.dis = lm(crim~poly(dis,2))
lm.dis
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(markdown)
knitr::opts_chunk$set(echo = TRUE)
library (MASS)
library (ISLR)
data(Auto)
pairs(Auto)
ggpairs(Auto,c[1:7])
library(ggpairs)
library(ggplot2)
ggpairs(Auto,c[1:7])
require(GGally)
install.packages(GGally)
install.packages("GGally")
ggpairs(Auto,c[1:7])
ggpairs(Auto)
install.packages("reshape")
ggpairs(Auto)
ggpairs(Auto,c[1:7])
setwd("~/Documents/UCD-pbio-rclub/ISLR_Hajar.Amini/Chapter3_Dec_20")
knitr::opts_chunk$set(echo = TRUE)
par(mfrow=c(2,2))
plot(lm.fit1)
lm.fit1 = lm(mpg~.-name, data=Auto)
knitr::opts_chunk$set(echo = TRUE)
library (MASS)
library (ISLR)
lm.fit1 = lm(mpg~.-name, data=Auto)
summary(lm.fit1)
par(mfrow=c(2,2))
plot(lm.fit1)
plot(predict(lm.fit1), rstudent(lm.fit1))
plot(predict(lm.fit1)
>
quit
>
data("Auto")
Auto
lm.fit2 = lm(mpg~cylinders*displacement+displacement*weight)
lm.fit2 = lm(mpg~cylinders*displacement+displacement*weight, data = Auto)
lm.fit2
summary(lm.fit2)
lm.fit3 = lm(mpg~log(weight)+sqrt(horsepower)+acceleration+I(acceleration^2))
lm.fit3 = lm(mpg~log(weight)+sqrt(horsepower)+acceleration+I(acceleration^2), data = Auto)
summary(lm.fit3)
par(mfrow=c(2,2))
plot(lm.fit3)
plot(predict(lm.fit3), rstudent(lm.fit3))
plot(lm.fit3)
lm.fit2<-lm(log(mpg)~cylinders+displacement+horsepower+weight+acceleration+year+origin,data=Auto)
summary(lm.fit2)
par(mfrow=c(2,2))
plot(lm.fit2)
plot(predict(lm.fit2),rstudent(lm.fit2))
plot(predict(lm.fit3), rstudent(lm.fit3))
plot(predict(lm.fit2),rstudent(lm.fit2))
lm.fit2 = lm(Sales ~ Price + US)
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(markdown)
library (MASS)
library (ISLR)
data(Auto)
pairs(Auto)
lm.fit2 = lm(Sales ~ Price + US)
lm.fit2 = lm(Sales ~ Price + US)
lm.fit2 = lm(sales ~ price + US)
library(MASS)
summary(Boston)
Boston
Auto
library(ISLR)
summary(Carseats)
library(ISLR)
summary(Carseats)
summary(Carseats)
lm.fit2 = lm(sales ~ price + US)
lm.fit2 = lm(Sales ~ Price + US)
lm.fit2 = lm(Sales ~ Price + US, data = Carseats)
summary(lm.fit2)
plot(predict(lm.fit2), rstudent(lm.fit2))
par(mfrow=c(2,2))
plot(lm.fit2)
lm.fit1 = lm(mpg~.-name, data=Auto)
summary(lm.fit1)
par(mfrow=c(2,2))
plot(lm.fit1)
#The fit does not appear to be accurate because there is an obvious curve pattern to the residuals plots. From the leverage plot, point 14 appears to have high leverage, without a high magnitude residual.
plot(predict(lm.fit1), rstudent(lm.fit1))
#There are possible outliers regarding  plot of studentized residuals because there are data with a value greater than 3.
library (MASS)
library (ISLR)
data(Auto)
library (MASS)
library (ISLR)
data(Auto)
lm.fit1 = lm(mpg~.-name, data=Auto)
summary(lm.fit1)
par(mfrow=c(2,2))
plot(lm.fit1)
#The fit does not appear to be accurate because there is an obvious curve pattern to the residuals plots. From the leverage plot, point 14 appears to have high leverage, without a high magnitude residual.
plot(predict(lm.fit1), rstudent(lm.fit1))
#There are possible outliers regarding  plot of studentized residuals because there are data with a value greater than 3.
lm.fit =lm(medv∼lstat+age ,data=Boston )
lm.fit =lm(medv∼lstat+age,data=Boston )
Boston
lm.fit =lm(medv∼lstat+age,data=Boston )
library (MASS)
library (ISLR)
lm.fit =lm(medv∼lstat+age,data=Boston )
lm.fit = lm(medv∼lstat+age,data=Boston )
lm.fit <- lm(data = Boston, medv~lstat+age)
summary(lm.fit)
lm.fit <- lm(medv~. , data=Boston)
summary(lm.fit)
summary(lm.fit)$r.sq
summary(lm.fit)$sigma
library (car)
install.packages(car)
install.packages("car")
library (car)
vif(lm.fit)
lm.fit1=lm(medv∼.-age ,data=Boston )
lm.fit1 >- lm(medv~.-age, data = Boston)
lm.fit1 >- lm(medv~. -age, data = Boston)
lm.fit1=lm(medv~. -age, data = Boston)
lm.fit1=lm(medv~.-age, data = Boston)
summary (lm.fit1)
lm.fit1=update (lm.fit , ∼.-age)
lm.fit1=update(lm.fit , ∼.-age)
lm.fit1=update(lm.fit, ∼.-age)
lm.fit1=update(lm.fit,∼.-age)
update()
lm.fit1=update (lm.fit,∼. -age)
lm.fit1= update (lm.fit,∼. -age)
lm.fit1=update(lm.fit, ~. -age)
lm.fit1
summary (lm(medv∼lstat *age ,data=Boston ))
summary(lm(medv~lstat *age, data = Boston))
lm.fit2=lm(medv∼lstat +I(lstat ^2))
lm.fit2=lm(medv~lstat + I(lstat^2))
lm.fit2=lm (medv~lstat + I(lstat^2))
lm.fit2=lm(medv~ lstat + I(lstat^2))
lm.fit2=lm(medv~lstat +I(lstat^2))
lm.fit2=lm(medv~lstat +I(lstat^2), data = Boston)
summary(lm.fit2)
lm.fit =lm(medv∼lstat, data=Boston)
lm.fit=lm(medv∼lstat, data=Boston)
lm.fit=lm(medv~lstat, data=Boston)
summary(lm.fit)
anova(lm.fit ,lm.fit2)
par(mfrow=c(2,2))
plot(lm.fit2)
lm.fit5=lm(medv∼poly(lstat ,5), data=Boston)
lm.fit5=lm(medv∼poly(lstat,5), data=Boston)
lm.fit5=lm(medv~ploy(lstat, 5), data = Boston)
lm.fit5=lm(medv~ ploy(lstat, 5), data = Boston)
lm.fit5=lm(medv~ poly(lstat, 5), data = Boston)
summary(lm.fit5)
summary (lm(medv∼log(rm),data=Boston ))
summary(lm(medv~log(rm), data = Boston))
fix( Carseats )
?fix
names(Carseats )
lm.fit =lm(Sales∼.+ Income :Advertising +Price :Age ,data=Carseats )
lm.fit=lm(Sales~.+Income:Advertising+Price:Age, data=Carseats)
summary (lm.fit)
attach (Carseats )
contrasts (ShelveLoc )
Carseats$
>
?attach
?contrasts
ShelveLocGood
contrasts (ShelveLoc )
Carseats$ShelveLoc
knitr::opts_chunk$set(echo = TRUE)
set.seed (1)
x1=runif (100)
x2 =0.5* x1+rnorm (100) /10
y=2+2* x1 +0.3* x2+rnorm (100)
Y = 2 + 2 X_1 + 0.3 X_2 + \epsilon \ \beta_0 = 2, \beta_1 = 2, \beta_3 = 0.3
y
cor(x1, x2)
plot(x1, x2)
lm.fit = lm(y~x1+x2)
summary(lm.fit)
lm.fit = lm(y~x1)
summary(lm.fit)
lm.fit = lm(y~x2)
summary(lm.fit)
summary (lm(medv ∼ lstat *age ,data=Boston ))
summary(lm(medv~lstat*age, data = Boston))
x1=c(x1 , 0.1)
x2=c(x2 , 0.8)
y=c(y,6)
lm.fit1 = lm(y~x1+x2)
summary(lm.fit1)
lm.fit2 = lm(y~x1)
summary(lm.fit2)
lm.fit3 = lm(y~x2)
summary(lm.fit3)
par(mfrow=c(2,2))
plot(lm.fit1)
par(mfrow=c(2,2))
plot(lm.fit2)
par(mfrow=c(2,2))
plot(lm.fit3)
plot(predict(lm.fit1), rstudent(lm.fit1))
plot(predict(lm.fit2), rstudent(lm.fit2))
plot(predict(lm.fit3), rstudent(lm.fit3))
plot(predict(lm.fit1), rstudent(lm.fit1))
plot(predict(lm.fit2), rstudent(lm.fit2))
load("/Users/hajaramini/Downloads/metaAnalysisFiles/metaAnalysisData.RData")
View(datExprA1)
View(datExprB2)
View(datExprB1)
View(datExprA2)
View(datExprB2)
View(datExprB1)
getwd()
setwd("Chapter4_Jan_23/")
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
lda.fit = lda(Direction ~ Lag2, data = Weekly, subset = train)
data(Weekly)
Weekly
library(ISLR)
lda.fit = lda(Direction ~ Lag2, data = Weekly, subset = train)
lda.fit = lda(Direction ~ Lag2, data = Weekly, subset = train)
lda.fit = lda(Direction ~ Lag2, data =  Weekly)
lda.fit = lda(Direction ~ Lag2, data =  Weekly, subset=train)
lda.fit <- lda(Direction~lag2, data = Weekly,subet=train)
lda.fit <- lda(Direction~ lag2, data = Weekly,subet=train)
lda.fit <- lda(Direction ~ lag2, data = Weekly,subet=train)
names(Smarket )
lda.fit = lda(Direction ~ Lag2, data = Weekly, subset = train)
train = (Year < 2009)
summary(Weekly)
train = (Year < 2009)
data(Weekly)
train = (Year < 2009)
train = (Weekly$Year < 2009)
lda.fit = lda(Direction ~ Lag2, data = Weekly, subset = train)
lda.pred = predict(lda.fit, Weekly.0910)
setwd("~/Documents/UCD-pbio-rclub/ISLR_Hajar.Amini/Chapter5_Feb_6")
knitr::opts_chunk$set(echo = TRUE)
library (ISLR)
set.seed (1)
train=sample (392 ,196)
?sample
lm.fit =lm(mpg∼horsepower ,data=Auto ,subset =train )
lm.fit =lm(mpg ∼ horsepower ,data=Auto ,subset =train )
lm.fit =lm (mpg ∼ horsepower ,data=Auto ,subset =train )
lm.fit =lm (mpg ∼ horsepower ,data=Auto , subset =train )
lm.fit =lm (mpg ∼ horsepower ,data=Auto , subset =train)
lm.fit <- lm(mpg~horsepower, data = Auto, subset = train)
attach (Auto)
mean((mpg -predict (lm.fit ,Auto))[-train ]^2)
lm.fit2=lm(mpg∼poly(horsepower ,2) ,data=Auto ,subset =train )
lm.fit2=lm(mpg~poly(horsepower ,2) ,data=Auto ,subset =train )
mean((mpg -predict (lm.fit2 ,Auto))[-train ]^2)
lm.fit3=lm(mpg~poly(horsepower ,3) ,data=Auto ,subset =train )
mean((mpg -predict (lm.fit3 ,Auto))[-train ]^2)
set.seed (2)
train=sample (392 ,196)
lm.fit =lm(mpg~horsepower ,subset =train)
mean((mpg -predict (lm.fit ,Auto))[-train ]^2)
lm.fit2=lm(mpg~poly(horsepower ,2) ,data=Auto ,subset =train )
mean((mpg -predict (lm.fit2 ,Auto))[-train ]^2)
lm.fit3=lm(mpg~poly(horsepower ,3) ,data=Auto ,subset =train )
mean((mpg -predict (lm.fit3 ,Auto))[-train ]^2)
glm.fit=glm(mpg~horsepower ,data=Auto)
coef(glm.fit)
lm.fit =lm(mpg∼horsepower ,data=Auto)
lm.fit =lm(mpg~horsepower ,data=Auto)
coef(lm.fit)
library (boot)
glm.fit=glm(mpg~horsepower ,data=Auto)
cv.err =cv.glm(Auto ,glm.fit)
cv.err$delta
cv.err =cv.glm(Auto ,glm.fit)
cv.err$delta
?cv.glm()
cv.err
head(cv.err)
head(cv.err$delta)
cv.error=rep (0,5)
cv.error
for (i in 1:5){
glm.fit=glm(mpg~poly(horsepower ,i),data=Auto)
cv.error[i]=cv.glm (Auto ,glm .fit)$delta [1]
for (i in 1:5){
glm.fit=glm(mpg~poly(horsepower ,i),data=Auto)
cv.error[i]=cv.glm (Auto ,glm .fit)$delta [1]
for (i in 1:5){
glm.fit=glm(mpg~poly(horsepower ,i),data=Auto)
cv.error[i]=cv.glm (Auto ,glm.fit)$delta [1]
}
cv.error
set.seed (17)
cv.error .10= rep (0 ,10)
cv.error.10= rep (0 ,10)
cv.error.10[1]
cv.error.10[2]
cv.error.10[10]
set.seed (17)
cv.error.10= rep (0 ,10)
for (i in 1:10) {
glm.fit=glm(mpg∼poly(horsepower ,i),data=Auto)
set.seed (17)
cv.error.10= rep (0 ,10)
for (i in 1:10) {
glm.fit=glm(mpg~poly(horsepower ,i),data=Auto)
cv.error.10[i]=cv.glm (Auto ,glm.fit ,K=10) $delta [1]
}
cv.error.10
knitr::opts_chunk$set(echo = TRUE)
library(ISLR)
IRLR
Default
summary(Default)
attach(Default)
set.seed(1)
binomial
?family
set.seed(1)
glm.fit = glm(default~income+balance, data=Default, family=binomial)
x = function() {
# i.
train = sample(dim(Default)[1], dim(Default)[1]/2)
# ii.
glm.fit = glm(default~income+balance, data=Default, family=binomial,
subset=train)
# iii.
glm.pred = rep("No", dim(Default)[1]/2)
glm.probs = predict(glm.fit, Default[-train,], type="response")
glm.pred[glm.probs>.5] = "Yes"
# iv.
return(mean(glm.pred != Default[-train,]$default))
}
x()
x()
x()
x()
train = sample(dim(Default)[1], dim(Default)[1]/2)
glm.fit = glm(default~income+balance+student, data=Default, family=binomial,subset=train)
glm.pred = rep("No", dim(Default)[1]/2)
glm.probs = predict(glm.fit, Default[-train,], type="response")
glm.pred[glm.probs>.5] = "Yes"
mean(glm.pred != Default[-train,]$default)
library(ISLR)
summary(Weekly)
set.seed(1)
attach(Weekly)
glm.fit = glm(Direction~Lag1+Lag2, data=Weekly, family=binomial)
summary(glm.fit)
Weekly[,]
Weekly[-1,]
rownames(Weekly)
glm.fit = glm(Direction~Lag1+Lag2, data=Weekly[-1,], family=binomial)
summary(glm.fit)
predict.glm(glm.fit, Weekly[1,], type="response") > 0.5
Weekly[1,]
count = rep(0, dim(Weekly)[1])
for (i in 1:(dim(Weekly)[1])) {
glm.fit = glm(Direction~Lag1+Lag2, data=Weekly[-i,], family=binomial)
is_up = predict.glm(glm.fit, Weekly[i,], type="response") > 0.5
is_true_up = Weekly[i,]$Direction == "Up"
if (is_up != is_true_up)
count[i] = 1
}
sum(count)
y = rep(0, dim(Weekly)[1])
for (i in 1:(dim(Weekly)[1])) {
glm.fit = glm(Direction~Lag1+Lag2, data=Weekly[-i,], family=binomial)
is_up = predict.glm(glm.fit, Weekly[i,], type="response") > 0.5
is_true_up = Weekly[i,]$Direction == "Up"
if (is_up != is_true_up)
count[i] = 1
}
sum(y)
#490 errors.
mean(y)
mean(y)
sum(y)
y = rep(0, dim(Weekly)[1])
for (i in 1:(dim(Weekly)[1])) {
glm.fit = glm(Direction~Lag1+Lag2, data=Weekly[-i,], family=binomial)
is_up = predict.glm(glm.fit, Weekly[i,], type="response") > 0.5
is_true_up = Weekly[i,]$Direction == "Up"
if (is_up != is_true_up)
y[i] = 1
}
sum(y)
#490 errors.
mean(y)
set .seed (1)
set.seed (1)
x=rnorm (100)
y=x-2* x^2+ rnorm (100)
plot(x,y)
library(boot)
Data = data.frame(x,y)
set.seed(1)
glm.fit = glm(y~x)
cv.glm(Data, glm.fit)$delta
glm.fit = glm(y~poly(x,2))
cv.glm(Data, glm.fit)$delta
glm.fit = glm(y~poly(x,3))
cv.glm(Data, glm.fit)$delta
glm.fit = glm(y~poly(x,4))
cv.glm(Data, glm.fit)$delta
set.seed(10)
glm.fit = glm(y~x)
cv.glm(Data, glm.fit)$delta
glm.fit = glm(y~poly(x,2))
cv.glm(Data, glm.fit)$delta
glm.fit = glm(y~poly(x,3))
glm.fit = glm(y~poly(x,3))
cv.glm(Data, glm.fit)$delta
glm.fit = glm(y~poly(x,4))
cv.glm(Data, glm.fit)$delta
summary(glm.fit)
